{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applied Deep Learning in Python using PyTorch\n",
    "\n",
    "This document outlines the process of training a Convolutional Neural Network (CNN) for image classification using PyTorch. It follows a structured workflow, starting with data loading and preprocessing, followed by model definition, training, evaluation, and testing.\n",
    "\n",
    "The dataset used in this project is MNIST, a collection of grayscale images of handwritten digits (0-9). All images are converted into PyTorch tensors for processing. The CNN architecture is designed for grayscale images and is trained using a loss function and an optimizer to improve its accuracy. The training loop includes validation steps to monitor the model’s performance.\n",
    "\n",
    "Additionally, the notebook checks for GPU availability. If a GPU is detected, computations are offloaded for faster processing; otherwise, training runs on the CPU. After training, the model is evaluated on a separate test dataset to assess its classification accuracy.\n",
    "\n",
    "This document is based on a template provided by Steven Edwards and serves as a foundation for image classification tasks using PyTorch. It can be adapted for other deep learning projects involving image recognition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Installing Packages and Connecting to GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 Install PyTorch with CUDA 12.1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you get \"Out of Memory\" errors when training your model. Use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import torch\n",
    "#torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code checks for CUDA availability, prints the GPU name if available, and assigns the computing device (cuda:0 or cpu) to device for later use in mounting the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 Connecting to GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.__version__)  # Check PyTorch version\n",
    "print(torch.version.cuda)  # Check CUDA version in PyTorch\n",
    "print(torch.backends.cudnn.enabled)  # Check if cuDNN is enabled\n",
    "\n",
    "print(torch.cuda.is_available())  # Should return True if CUDA is available\n",
    "print(torch.cuda.get_device_name(0))  # Should return the GPU name\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Loading and Transforming the `MNIST` Dataset\n",
    "\n",
    "For this project, I'm using the MNIST dataset, a collection of 28×28 grayscale images of handwritten digits (0-9). Instead of manually downloading and importing the dataset, I used PyTorch’s torchvision.datasets.MNIST, which allows for direct access and downloading.\n",
    "\n",
    "To prepare the dataset, I use PyTorch's built-in ToTensor transform, which converts the images into tensors. Since MNIST images are already a standard size of 28x28, no additional resizing is needed.\n",
    "\n",
    "I then create data loaders using PyTorch’s DataLoader class. This allows me to efficiently load the dataset in batches of 32 images at a time. Using batch processing is essential for training deep learning models, as it optimizes memory usage and speeds up computation, especially when training on a GPU. The training set contains 60,000 images, while the test set contains 10,000 images.\n",
    "\n",
    "Finally, I check if a GPU is available and set the device accordingly. If a GPU is present, the model and data will be processed on it; otherwise, it will fall back to the CPU. A quick verification prints the shape of the first batch to ensure everything is loaded correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 Loading the `MNIST` Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert images to tensors\n",
    "])\n",
    "\n",
    "# Load MNIST dataset\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Check dataset details\n",
    "print(f\"Number of training samples: {len(trainset)}\")  # Should be 60,000\n",
    "print(f\"Number of test samples: {len(testset)}\")    # Should be 10,000\n",
    "print(f\"Classes: {trainset.classes}\")               # Should be 0-9\n",
    "\n",
    "# Define batch size\n",
    "batch_size = 32  # Increased from 8\n",
    "\n",
    "# Create data loaders\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "# Set device to GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Example: Iterate through one batch to verify\n",
    "for images, labels in trainloader:\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    print(f\"Batch shape: {images.shape}\")  # Should be [8, 1, 28, 28] (batch_size, channels, height, width)\n",
    "    print(f\"Labels: {labels}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I verify what the shape of an individual tensor looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = iter(trainset)\n",
    "\n",
    "image, label = next(train_iter)\n",
    "\n",
    "image.shape, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, the labels and corresponding index values are confirmed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainset.class_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2 Visualizing Tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define class names (0-9 for MNIST)\n",
    "classes = [str(i) for i in range(10)]  \n",
    "\n",
    "index = 400  # Select an image by index\n",
    "\n",
    "image, label = trainset[index]  # Get the image and its label\n",
    "\n",
    "plt.imshow(image.permute(1, 2, 0), cmap=\"gray\")  # Use grayscale colormap\n",
    "plt.title(f\"Label: {classes[label]}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Preparing the Data for Training\n",
    "\n",
    "To evaluate model performance, we will use the predefined training and test sets provided by the MNIST dataset. Below, I confirm the sizes of both datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trainset), len(testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Create Subsets of Training Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the original trainset into two parts: 80% for training and 20% for validation\n",
    "trainset, valset = torch.utils.data.random_split(trainset, [48000, 12000])\n",
    "\n",
    "# Verify the sizes of the new train and validation sets\n",
    "print(f\"New training set size: {len(trainset)}\")  # Should be 48,000 (80% of 60,000)\n",
    "print(f\"Validation set size: {len(valset)}\")     # Should be 12,000 (20% of 60,000)\n",
    "\n",
    "# Check that the testset remains unchanged\n",
    "print(f\"Test set size: {len(testset)}\")  # Should be 10,000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code prints the number of batches our data will be divided into during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_batches_train = len(trainset) // batch_size\n",
    "num_batches_test = len(testset) // batch_size\n",
    "print(f'Number of batches in the training set: {num_batches_train}')\n",
    "print(f'Number of batches in the test set: {num_batches_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Model Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " PyTorch requires a data loader when using a GPU for model training. This section sets up the data loaders, which are efficient modules for moving our data from the CPU onto the GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1 Setup Data Loaders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size,\n",
    "                                          shuffle=False, num_workers=2)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we are building a Convolutional Neural Network (CNN) for image classification using the MNIST dataset, which consists of 28x28 grayscale images of handwritten digits (0-9).\n",
    "\n",
    "**The model is defined as a class in PyTorch, and consists of two main parts:**\n",
    "\n",
    "`1. Layers Definition:` This part defines the layers of the model, including convolutional layers, max pooling layers, linear layers, and dropout layers. The output channels of one layer must match the input channels of the next.\n",
    "\n",
    "`2. Forward Function:` This function defines how the data flows through the model, layer by layer. It also specifies activation functions (such as ReLU) that introduce non-linearity into the model, helping it learn more complex patterns in the data.\n",
    "\n",
    "**Convolutional Layers**\n",
    "In a CNN, the convolutional layers (e.g., self.conv1, self.conv2, self.conv3) apply filters to the input image to highlight important features, like edges and textures. Each convolution operation creates feature maps by sliding a filter across the image, performing a mathematical operation at each position. The Conv2d class in PyTorch is used to define these convolutional layers.\n",
    "\n",
    "For MNIST, the input images are 28x28 pixels and have a single channel (grayscale). In the first convolutional layer (self.conv1), the input channels are set to 1 (for grayscale), and the output channels are set to 32. The output channels represent different feature maps generated by the filters.\n",
    "\n",
    "After each convolution, the output is passed through a ReLU activation function to introduce non-linearity. ReLU helps the model learn more complex patterns by turning negative values to zero while keeping positive values unchanged.\n",
    "\n",
    "**Max Pooling Layers**\n",
    "Max pooling layers (MaxPool2d) are used after the convolutional layers to downsample the feature maps. Pooling reduces the dimensionality of the data, making the model more efficient and less complex while retaining the most important features. In this model, we use a 2x2 pooling window to reduce the spatial size of the feature maps.\n",
    "\n",
    "Why This Architecture Works for MNIST\n",
    "The convolutional layers help the model learn spatial hierarchies in the image, such as edges, shapes, and digits, while the pooling layers help reduce computational complexity. This combination of convolution, activation, and pooling layers is ideal for the MNIST dataset, as it allows the model to efficiently extract important features while maintaining computational efficiency. The fully connected layers then help classify the features into one of the 10 digit categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2 Define CNN Architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=5, padding=2)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=5, padding=2)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.conv3 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=4, padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Calculate the size of the flattened features after all convolutional and pooling layers\n",
    "        self._flattened_features = self._get_conv_output_size()\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(in_features=self._flattened_features, out_features=1024)\n",
    "        self.drop1 = nn.Dropout(p=0.3)\n",
    "        self.fc2 = nn.Linear(in_features=1024, out_features=512)\n",
    "        self.drop2 = nn.Dropout(p=0.3)\n",
    "        self.out = nn.Linear(in_features=512, out_features=10) # out_features match class labels\n",
    "\n",
    "    def _get_conv_output_size(self):\n",
    "        # Create a dummy input to pass through the convolutional layers only\n",
    "        dummy_input = torch.zeros(1, 1, 28, 28)  # Use the provided input dimensions\n",
    "        dummy_input = self.conv1(dummy_input)\n",
    "        dummy_input = self.pool1(dummy_input)\n",
    "        dummy_input = self.conv2(dummy_input)\n",
    "        dummy_input = self.pool2(dummy_input)\n",
    "        dummy_input = self.conv3(dummy_input)\n",
    "        dummy_input = self.pool3(dummy_input)\n",
    "        return int(torch.flatten(dummy_input, 1).size(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolutional and pooling layers\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        # Flatten the output for the fully connected layers\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        # Fully connected layers with ReLU activations and dropout\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.drop1(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.drop2(x)\n",
    "\n",
    "        # Output layer\n",
    "        x = self.out(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the model will run on a GPU, I need to push it to the GPU, which is not necessary for CPU-only training. \n",
    "\n",
    "Additionally, I'll check the shape of the input and output features to ensure they match the model architecture, with the output having the defined batch size and the correct number of class labels (10 in my dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.3 Push Model to Device and Verify Parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuralNet()\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code checks the shape of my initial inputs and my final outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(trainloader):\n",
    "    inputs, labels = data[0].to(device), data[1].to(device)\n",
    "    print(f'input shape: {inputs.shape}')\n",
    "    print(f'after network shape: {net(inputs).shape}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check how many parameters my CNN will estimate, I can calculate the total number. This number is often large and may cause out-of-memory errors. To address this, try reducing the batch size or simplifying the model by decreasing the number of channels in the layers. However, ensure consistency in the architecture. This can be tricky and requires careful adjustments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_params = 0\n",
    "for x in net.parameters():\n",
    "  num_params += len(torch.flatten(x))\n",
    "\n",
    "print(f'Number of parameters in the model: {num_params:,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Select Loss Function and Optimization Technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm using CrossEntropyLoss as the loss function for multi-class classification. The loss function measures how well the model's predictions match the true labels, and the learning rate controls how aggressively the model updates its parameters during training. Experimenting with different learning rates and loss functions can help improve model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.1 Loss Function and Learning Rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Define and Run the Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training deep learning models can be challenging due to computational bottlenecks, especially with complex models and large datasets. To optimize training, we process data in batches and iterate over them in epochs. This prevents GPU memory overload and allows real-time reporting of loss and accuracy. Defining how epochs run and track progress is essential, with a separate validation epoch typically used after training on the training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.1 Setup Training Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch():\n",
    "    print(\"Starting training epoch...\")\n",
    "    net.train(True)\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_accuracy = 0.0\n",
    "    batch_count = 0\n",
    "    \n",
    "    for batch_index, data in enumerate(trainloader):\n",
    "        batch_count += 1\n",
    "        \n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = net(inputs)\n",
    "        correct = torch.sum(labels == torch.argmax(outputs, dim=1)).item()\n",
    "        running_accuracy += correct / batch_size\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        running_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_index % 20 == 19:  # print every 20 batches\n",
    "            avg_loss_across_batches = running_loss / 20\n",
    "            avg_acc_across_batches = (running_accuracy / 20) * 100\n",
    "            print('Batch {0}, Loss: {1:.3f}, Accuracy: {2:.1f}%'.format(\n",
    "                batch_index + 1, avg_loss_across_batches, avg_acc_across_batches))\n",
    "            running_loss = 0.0\n",
    "            running_accuracy = 0.0\n",
    "    \n",
    "    print(f\"Total batches processed: {batch_count}\")\n",
    "    print(\"Finished training epoch.\")\n",
    "\n",
    "# Call the function\n",
    "train_one_epoch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.2 Setup Validation Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_one_epoch():\n",
    "    try:\n",
    "        print(\"Starting validation epoch...\")\n",
    "        net.train(False)\n",
    "        running_loss = 0.0\n",
    "        running_accuracy = 0.0\n",
    "        total_samples = 0\n",
    "        \n",
    "        print(f\"Number of batches in valloader: {len(valloader)}\")\n",
    "        \n",
    "        for i, data in enumerate(valloader):\n",
    "            print(f\"Processing validation batch {i + 1}\")\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = net(inputs)\n",
    "                correct = torch.sum(labels == torch.argmax(outputs, dim=1)).item()\n",
    "                running_accuracy += correct\n",
    "                total_samples += len(labels)\n",
    "                loss = criterion(outputs, labels)\n",
    "                running_loss += loss.item()\n",
    "        \n",
    "        avg_loss_across_batches = running_loss / len(valloader)\n",
    "        avg_acc_across_batches = (running_accuracy / total_samples) * 100\n",
    "        \n",
    "        print('Val Loss: {0:.3f}, Val Accuracy: {1:.1f}%'.format(\n",
    "            avg_loss_across_batches, avg_acc_across_batches))\n",
    "        print('***************************************************')\n",
    "        print()\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during validation: {e}\")\n",
    "\n",
    "# Call the function after training\n",
    "validate_one_epoch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have defined our training and validation loops, we can train our model. We will run 10 epochs to optimize its performance and improve accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.1 Run Epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch_index in range(num_epochs):\n",
    "    print(f'Epoch: {epoch_index + 1}\\n')\n",
    "    \n",
    "    train_one_epoch()\n",
    "    validate_one_epoch()\n",
    "    \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Evaluate the Model\n",
    "\n",
    "After training, our model can be evaluated like any classification model. Key metrics include classification accuracy, true/false positive and negative rates. These metrics can be visualized using a confusion matrix with `matplotlib` and `seaborn`. We will use various metrics from sklearn to assess performance by running our test dataset through the model, generating predictions, and comparing them to the actual class labels to identify errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Get predicted labels from the model\n",
    "predicted_labels = []\n",
    "true_labels = []\n",
    "\n",
    "# Iterate through test set and collect predictions\n",
    "for images, labels in testloader:\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    outputs = net(images)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    predicted_labels.extend(predicted.cpu().numpy())\n",
    "    true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Generate classification report\n",
    "class_report = classification_report(true_labels, predicted_labels, target_names=classes)\n",
    "\n",
    "\n",
    "# Generate confusion matrix\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification Report:\\n\", class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, the confusion matrix is visualized with more formatting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Extract class labels from the dataset\n",
    "class_labels = testset.classes\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.set(font_scale=1.2)  # Set font scale\n",
    "sns.heatmap(conf_matrix, annot=True, cmap=\"Blues\", fmt=\"d\", xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel(\"Predicted labels\")\n",
    "plt.ylabel(\"True labels\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Saving the Trained Model\n",
    "\n",
    "The metrics indicate that our model performs exceptionally well. To avoid retraining it each time we want to make predictions on new data, we can save the model as a .pth file in the models folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define the directory path to save the model\n",
    "save_dir = r\"C:/Users/ryanj/Desktop/COGS/2010/project_2\"\n",
    "\n",
    "# Define the file name for the saved model\n",
    "model_name = \"mnist_epoch10.pth\"\n",
    "save_path = os.path.join(save_dir, model_name)\n",
    "\n",
    "# Save the model\n",
    "torch.save(net.state_dict(), save_path)\n",
    "\n",
    "print(f\"Model saved at: {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I can load this model into my project separately, and test it on the same test data to make sure it is working:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "# Define the model architecture\n",
    "net_test = NeuralNet()  # Ensure NeuralNet is defined elsewhere in your code\n",
    "\n",
    "# Define the directory path and model name\n",
    "save_dir = r\"C:/Users/ryanj/Desktop/COGS/2010/project_2\"\n",
    "model_name = \"mnist_epoch10.pth\"\n",
    "save_path = os.path.join(save_dir, model_name)\n",
    "\n",
    "# Load the saved model state dictionary\n",
    "net_test.load_state_dict(torch.load(save_path))\n",
    "\n",
    "# Move the model to the GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net_test.to(device)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "net_test.eval()\n",
    "\n",
    "# Initialize counters for correct predictions and total samples\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# Disable gradient calculation for evaluation\n",
    "with torch.no_grad():\n",
    "    for images, labels in testloader:\n",
    "        # Move images and labels to the GPU\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass: Get model outputs\n",
    "        outputs = net_test(images)\n",
    "        \n",
    "        # Get the predicted class with the highest score\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        # Update total samples and correct predictions\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Accuracy of the network on the test images: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion:\n",
    "\n",
    "In this project, we successfully developed and trained a convolutional neural network (CNN) to classify handwritten digits from the MNIST dataset. The model achieved an impressive accuracy of **99.33%** on the test set, demonstrating its effectiveness in recognizing digit patterns. We implemented robust training and validation loops, utilized appropriate loss functions and optimizers, and evaluated the model's performance using various metrics, including a confusion matrix and classification report. Finally, we saved the trained model for future use, ensuring that it can be easily loaded and utilized for making predictions without the need for retraining. Overall, the project highlights the power of deep learning in image classification tasks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
