<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Deep Learning with PyTorch</title>
  <link rel="stylesheet" href="style.css" />
  <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@300;400;700&display=swap" rel="stylesheet">
  <!-- Prism.js for syntax highlighting -->
  <link href="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/themes/prism-tomorrow.css" rel="stylesheet" />
  <script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/prism.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/components/prism-python.min.js"></script>

  <style>
    /* Add some basic styling for the container */
    .container {
      max-width: 800px;
      margin: 0 auto;
      padding: 20px;
      font-family: 'Poppins', sans-serif;
    }

    /* Styling for code blocks to make them scrollable */
    pre {
      background-color: #f5f5f5;
      padding: 15px;
      border-radius: 5px;
      overflow-y: auto;  /* Enables vertical scrolling */
      max-height: 400px; /* Limits the height of the code block */
      font-size: 10px;
      line-height: 1.5;
    }

    code {
      display: block;
    }

    /* Optional: Add syntax highlighting styles */
    .language-python {
      background-color: #2d2d2d;
      color: #f8f8f2;
      padding: 15px;
      border-radius: 5px;
    }

  </style>
</head>
<body>
  <div class="container">
    <h1>Deep Learning with PyTorch</h1>
    <p>
      This project outlines the process of training a Convolutional Neural Network (CNN) for image classification using PyTorch. 
      The workflow includes data loading and preprocessing, model definition, training, evaluation, and testing.
    </p>
    <p>
      The dataset used is MNIST—a collection of grayscale images of handwritten digits (0–9). All images are converted into 
      PyTorch tensors for processing. The CNN is designed for grayscale inputs and is trained using a loss function and optimizer 
      to improve classification accuracy. The training loop includes validation steps to monitor performance.
    </p>
    <p>
      <strong>Note:</strong> Selected code snippets are included below to highlight key parts of the project. The complete Jupyter Notebook, 
      including all code and outputs, is available using the link at bottom of the page.
    </p>
    
    <h2>Code Snippet 1</h2>
    <pre><code class="language-python">
      """Connecting to GPU"""

      """ Description:
          This module attempts to connect to the GPU.
          - Checks PyTorch version
          - Checks CUDA version and if cuDNN is enabled
          - Returns the GPU name, if successful
      """
      import torch
      
      print(torch.__version__)
      print(torch.version.cuda)
      print(torch.backends.cudnn.enabled)
      
      print(torch.cuda.is_available())
      print(torch.cuda.get_device_name(0))
      
      device = "cuda:0" if torch.cuda.is_available() else "cpu"
    </code></pre>

    <h2>Code Snippet 2</h2>
    <pre><code class="language-python">
      """Loading the MNIST Dataset"""

      """ Description:
          This module loads the MNIST dataset.
          - Checks dataset details
          - Defines batch size
          - Creates data loaders
          - Sets device to GPU
          - Iterates through one batch to verify
      """
      
      import torch
      import torchvision
      from torchvision import transforms
      from torch.utils.data import DataLoader
      
      transform = transforms.Compose([
          transforms.ToTensor(),  
      ])
      
      trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)
      testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)
      
      print(f"Number of training samples: {len(trainset)}")  
      print(f"Number of test samples: {len(testset)}")    
      print(f"Classes: {trainset.classes}")               
      
      batch_size = 32  
      
      trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)
      testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)
      
      device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
      print(f"Using device: {device}")

      for images, labels in trainloader:
          images, labels = images.to(device), labels.to(device)
          print(f"Batch shape: {images.shape}")  # Should be [8, 1, 28, 28] (batch_size, channels, height, width)
          print(f"Labels: {labels}")
          break
    </code></pre>

    <h2>Code Snippet 3</h2>
    <pre><code class="language-python">
      """Define CNN Architecture"""

      """ Description:
          This module defines a Convolutional Neural Network (CNN) for the MNIST dataset.
          - Implements a neural network with three convolutional layers, each followed by max pooling
          - Includes fully connected layers with dropout for classification
          - Configures input and output dimensions for MNIST (28x28 grayscale images, 10 classes)
          - Calculates flattened feature size dynamically for the fully connected layers
          - Uses ReLU activations and dropout for regularization
      """

      import torch
      import torch.nn as nn
      import torch.nn.functional as F

      class NeuralNet(nn.Module):
          def __init__(self):
              super().__init__()

              self.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=5, padding=2)
              self.pool1 = nn.MaxPool2d(2, 2)
              self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=5, padding=2)
              self.pool2 = nn.MaxPool2d(2, 2)
              self.conv3 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=4, padding=1)
              self.pool3 = nn.MaxPool2d(2, 2)

              self._flattened_features = self._get_conv_output_size()

              self.fc1 = nn.Linear(in_features=self._flattened_features, out_features=1024)
              self.drop1 = nn.Dropout(p=0.3)
              self.fc2 = nn.Linear(in_features=1024, out_features=512)
              self.drop2 = nn.Dropout(p=0.3)
              self.out = nn.Linear(in_features=512, out_features=10)

          def _get_conv_output_size(self):
              dummy_input = torch.zeros(1, 1, 28, 28)
              dummy_input = self.conv1(dummy_input)
              dummy_input = self.pool1(dummy_input)
              dummy_input = self.conv2(dummy_input)
              dummy_input = self.pool2(dummy_input)
              dummy_input = self.conv3(dummy_input)
              dummy_input = self.pool3(dummy_input)
              return int(torch.flatten(dummy_input, 1).size(1))

          def forward(self, x):
              x = F.relu(self.conv1(x))
              x = self.pool1(x)
              x = F.relu(self.conv2(x))
              x = self.pool2(x)
              x = F.relu(self.conv3(x))
              x = self.pool3(x)

              x = torch.flatten(x, 1)

              x = F.relu(self.fc1(x))
              x = self.drop1(x)
              x = F.relu(self.fc2(x))
              x = self.drop2(x)

              x = self.out(x)

              return x
    </code></pre>

    <h2>Code Snippet 4</h2>
    <pre><code class="language-python">
      """CNN Training Function"""

      """ Description:
          This module defines a function to train a Convolutional Neural Network (CNN) for one epoch on the MNIST dataset.
          - Processes batches from the training data loader
          - Computes loss and accuracy for each batch
          - Updates model parameters using the optimizer
          - Prints average loss and accuracy every 20 batches
          - Tracks and reports total batches processed
      """

      def train_one_epoch():
          print("Starting training epoch...")
          net.train(True)
          
          running_loss = 0.0
          running_accuracy = 0.0
          batch_count = 0
          
          for batch_index, data in enumerate(trainloader):
              batch_count += 1
              
              inputs, labels = data[0].to(device), data[1].to(device)
              
              optimizer.zero_grad()
              
              outputs = net(inputs)
              correct = torch.sum(labels == torch.argmax(outputs, dim=1)).item()
              running_accuracy += correct / batch_size
              
              loss = criterion(outputs, labels)
              running_loss += loss.item()
              loss.backward()
              optimizer.step()
              
              if batch_index % 20 == 19: 
                  avg_loss_across_batches = running_loss / 20
                  avg_acc_across_batches = (running_accuracy / 20) * 100
                  print('Batch {0}, Loss: {1:.3f}, Accuracy: {2:.1f}%'.format(
                      batch_index + 1, avg_loss_across_batches, avg_acc_across_batches))
                  running_loss = 0.0
                  running_accuracy = 0.0
          
          print(f"Total batches processed: {batch_count}")
          print("Finished training epoch.")

      train_one_epoch()
    </code></pre>

    <h2>Code Snippet 5</h2>
    <pre><code class="language-python">
      """CNN Training and Evaluation"""

      """ Description:
          This module trains and evaluates a Convolutional Neural Network (CNN) on the MNIST dataset.
          - Trains the model over multiple epochs
          - Validates the model after each epoch
          - Collects predictions from the test set
          - Computes accuracy, classification report, and confusion matrix
      """

      from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

      num_epochs = 10

      for epoch_index in range(num_epochs):
          print(f'Epoch: {epoch_index + 1}\n')
          
          train_one_epoch()
          validate_one_epoch()
          
      print('Finished Training')

      predicted_labels = []
      true_labels = []

      for images, labels in testloader:
          images = images.to(device)
          labels = labels.to(device)
          outputs = net(images)
          _, predicted = torch.max(outputs, 1)
          predicted_labels.extend(predicted.cpu().numpy())
          true_labels.extend(labels.cpu().numpy())

      accuracy = accuracy_score(true_labels, predicted_labels)
      print("Accuracy:", accuracy)

      class_report = classification_report(true_labels, predicted_labels, target_names=classes)

      conf_matrix = confusion_matrix(true_labels, predicted_labels)
    </code></pre>
    
    <h2>Summary</h2>
    <p>
      This project features a deep learning model built with PyTorch to recognize handwritten digits 
      from the MNIST dataset, achieving an accuracy of 99.33%. I created a neural network to 
      classify images of digits (0–9), using efficient data processing and GPU acceleration. The model 
      was trained and tested , and its performance was evaluated with detailed metrics.
    </p>

  <a href="https://github.com/ryanjamesmilia/deep_learning_pytorch/tree/main" target="_blank">
    Visit the Deep Learning with Pytorch Project on GitHub
  </a>
</section>
  
    <p><a href="https://ryanjamesmilia.github.io/#portfolio">← Back to Portfolio</a></p>
  </div>
</body>
</html>
